---
title: MySQL
toc: true
date: 2022-05-13 08:45:58
tags: MySQL
categories: database
---

## 架构

### 服务层 + 存储引擎层

- 一条查询 sql 的执行过程
  - 客户端发出查询命令
  - 连接器: 连接管理,权限验证
  - 查询缓存: 可选择开启,开启后先查询缓存(MySQL8.0 版本直接将查询缓存的整块功能删掉了).在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空
  - 分析器: 词法分析,语法分析
  - 优化器: 执行计划生成,索引选择
  - 执行器: 操作引擎,返回结果
  - 存储引擎: 保存数据,提供读写接口

### redo log（重做日志）和 binlog（归档日志）

- WAL
  - 写内存，再写日志（redo log）。定时或在某些情况（日志写满时）将内存数据批量刷到磁盘。
- Redo Log
  - 写 Log 过程
    - 写 redo buffer 内存
    - 根据 innodb_flush_log_at_trx_commit 参数配置（1 表示事务提交后同步 redo log 到磁盘，可以保证事务的持久性，其他配置无法保证）将 redo buffer 内容顺序写入 redo log 文件
    - redo log 文件大小固定，循环顺序擦写
  - 记录物理页更改（“在某个数据页上做了什么修改”）
  - Innodb 独有
  - crash-safe（由两阶段提交保证）
- Bin Log
  - 归档日志（原始 SQL 语句）
  - Server 层的能力
- 两阶段提交（保证数据库一致性）
  - 过程：写 redo log，prepare（引擎）-》写 bin log 得到 xid（server）-》提交事务，commit（引擎）
  - 数据恢复：bin log 中有 xid 的记录恢复，其中 redo log 记录处于 prepare 状态的自动提交。
  - 数据回滚：bin log 中没有 xid 的回滚。
- Mysql 参数
  - innodb_flush_log_at_trx_commit 1 表示事务提交后同步 redo log 到磁盘
  - sync_binlog 1 表示事务提交后同步 bin log 到磁盘

## 隔离级别

### 事务 4 种隔离级别（原理）

- RU 读未提交（最近记录）
- RC 读已提交（MVCC）
- RR 可重复读（MVCC）
- S 串行化（锁）

### MVCC

- 优点：写写互斥、读写不互斥
- 实现：
  - 原理：根据当前的 Read View 信息在事务回滚链中一直往前找，直到找到合适的记录
- 隐藏列：聚簇索引中的隐藏字段
  - trx_id：当前行最近被那个事务改变
  - roll_pointer：当前行旧版本在 undo log 位置的指针
- Read View：当前未提交事务的视图
  - 创建时机：
    - RC：每次读语句开始前新建
    - RR：当前事务开始前创建
  - 内容：
    - m_ids：当前活跃的读写事务 id 列表
    - min_trx_id：m_ids 中的最小值
    - max_trx_id：m_ids 中的最大值
    - creator_trx_id：当前事务 id
- Undo Log：事务回滚链路
  - 单条记录内容：
    - 变更结果
    - trx_id：执行变更的事务 id
    - roll_pointer：回滚指针
  - 记录删除时机
    - 不被需要时（记录的 trx_id 小于满足所有 Read View 要求的最小 min_trx_id）
- 合适记录的 trx_id 标准
  - = creator_trx_id
  - < min_trx_id
  - between min_trx_id and max_trx_id and not in m_ids

### 事务创建方式

- set autocommit=1、begin、commit work and chain、commit、rollback
- set autocommit=0、begin、commit、rollback

### 长事务

- 危害：undo log 文件过大、回滚段过长、锁占用过长
- 排查：information_schema.innodb_trx 表

## 索引

### 提高读写效率的数据结构

- 哈希表
  - 键-值（key-value）存储数据的结构,hash 冲突拉链解决
  - 优点: 等值增删改查快
  - 缺点: 不是有序的,区间查询慢
  - 适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎
- 有序数组
  - 优点: 查询,修改快(等值,区间)
  - 缺点: 插入删除慢
  - 只适用于静态存储引擎
- 搜索树
  - 影响因素：树高，数据磁盘密度（n 叉树）
  - 优点: 读写均衡,TC=O(logN)
- 其他
  - 跳表
  - LSM 树

### InnoDB 的索引模型

- 表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表.每一个索引在 InnoDB 里面对应一棵 B+树。
- 文中“以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。”---猜测这个 1200 计算方式是，innodb 默认页大小是 16kb，而一个页可以存放记录也可以存放索引+指针，索引类型为 bigint，占用 8 字节，指针默认是 6 字节。16k/(8+6)=1170
- 索引类型
  - 主键索引,也被称为聚簇索引（clustered index）,叶子节点存的是整行数据
  - 非主键索引,也被称为二级索引（secondary index）,叶子节点内容是主键的值,查询非索引字段需要回表(搜索两棵 B+树)
- 索引维护
  - 页分裂: 影响性能,降低空间利用率
  - 页合并
  - 自增主键:
    - 优点: 有序插入,性能好,不会触发页分裂;存储空间占用小(int-4 字节,bigint-8 字节)
- 联合索引
  - 覆盖索引: 查询索引树中保存的字段(索引+主键)
  - 最左前缀原则
  - 索引下推: MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。
- 普通索引和唯一索引，应该怎么选择？
  - 查询过程: 基本一致
  - 更新过程: 普通索引可以使用 change buffer,减少了随机磁盘访问，所以对更新性能的提升是会很明显的
  - 结论: 尽量使用普通索引
- change buffer 的使用场景
  - 写多读少类系统
  - 对比 redo log: redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。
- 怎么给字符串加索引?
  - 空间和时间的权衡
  - 1.完整索引:
    - 优点: 扫描行数少,可使用覆盖索引
    - 缺点: 占用更多空间
  - 2.前缀索引
    - 优点:节省空间;
    - 缺点:增加扫描行数,无法使用覆盖索引
    - 保证区分度尽可能高的前提下(>95%),长度尽可能短
  - 2.其他方式:
    - 倒序存储
    - hash 字段
    - 相同点: 只支持等值查询,不支持范围查询
    - 区别:
      - 存储空间: 差不多
      - CPU 消耗: hash > 倒序
      - 查询效率: hash 更稳定,扫描行数 < 倒序

### 选错索引怎么解决?

- show index 查看索引基数 cardinality,基数越大，索引的区分度越好。
  - 抽样统计: 选择 N 个数据页,当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。
- 扫描行数,explain 查看
- 1.索引统计信息不准确: 用 analyze table 来解决
- 2.优化器误判:
  - 1)force index;
  - 2)改写 sql;
  - 3)增加或者删除索引

### 锁

- 按加锁范围划分: 全局锁,表级锁,行锁
- 1.全局锁: Flush tables with read lock (FTWRL),保证读取时数据的一致性。
- 保证读一致性的方法
  - 全局锁（Mysql 层面提供）
  - 可重复读（Innodb 提供）
  - set global readonly=true（Mysql 层面提供）
- 2.表级锁
  - 表锁:
    - 加锁方式：lock table xxx read/write（加读锁或写锁）
    - 解锁方式：unlock tables xxx
    - 加锁影响：
      - 读锁：当前线程：只读，其他线程：只读
      - 写锁：当前线程：读写，其他线程：无法操作
  - 元数据锁（meta data lock，MDL): MySQL 5.5 引入
    - 加锁方式：自动加，DML 语句加 MDL 读锁，DDL 加 MDL 写锁
    - 释放：DML 语句事务结束时释放 MDL 读锁
    - 注意: 可能锁表,建议使用 DDL NOWAIT/WAIT n 语法
- 3.Innodb 行锁
  - 加锁时间：单行读写时
  - 解锁时间：事务提交之后（两阶段锁协议）
- 行锁的优化
  - 减少加锁时间（锁冲突操作在事务中越晚执行越好）
  - 减小锁的粒度（将容易发生行锁冲突的行 变为 多行，用多行表示一行）
- 行锁死锁
  - 原因：不同事务对锁出现循环依赖
  - 解决办法：
    - 死锁检测（银行家算法），复杂度 O（n），对应 Mysql 配置 innodb_deadlock_detect，默认为 on
    - 锁等待超时，超时后将本事务回滚，释放已有锁资源。缺点：等待时间设置多短容易误伤正常等待事务。对应 Mysql 配置的 innodb_lock_wait_timeout 配置
- 高并发场景下的死锁检测导致 CPU 负载高、事务并发量低
  - 解决办法
    - 应用中做并发控制、减少死锁检测算法耗时
    - 表结构设计中减小锁的粒度
- RR 事务视图可见性判断
  - 版本未提交，不可见；
  - 版本已提交，但是是在视图创建后提交的，不可见；
  - 版本已提交，而且是在视图创建前提交的，可见。
- 更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）

- B 树和 B+树的区别,为什么 mysql 要用 B+树,mongodb 要用 B 树

## 锁

- 共享锁,排它锁
- 记录锁,间隙锁,临键锁

## 慢查询排查

### 性能抖动

- 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长
- redo log 写满,要 flush 脏页,会阻塞所有更新操作
- 解决方案: 刷脏页的控制策略

### 内存页 Page

- 三种状态:
  - 第一种是，还没有使用的；
  - 第二种是，使用了并且是干净页；
  - 第三种是，使用了并且是脏页(内存数据页跟磁盘数据页内容不一致)
- 刷脏页: 内存数据写入到磁盘
  - 触发时机:
    - 后台线程自动 flush
    - 数据页淘汰而触发 flush
  - 控制策略
    - innodb_io_capacity: 告诉 InnoDB 你的磁盘能力
    - innodb_max_dirty_pages_pct: 脏页比例上限，默认值是 75%
    - innodb_flush_neighbors: 是否刷相邻的脏页,对机械硬盘有意义,ssd 不需要,8.0 后默认为 0

## 表数据删除

### 数据存储

### 只查询一行

- 1.查询长时间不返回
  - 等 MDL 锁,show processlist 查看, select blocking_pid from sys.schema_table_lock_waits,找到 process id 直接 kill
  - 等 flush
  - 等行锁,当前读会被写锁堵住,MySQL 5.7 版本，可以通过 sys.innodb_lock_waits 表查到。
- 2.查询慢
  - 没索引,扫描行数多,查询慢
  - 一致性读时,视图版本过多,导致需通过 undo log 回溯数据

## 集群

### 垂直拆分

- 垂直分表: 也就是大表拆小表，基于列字段进行的。
- 垂直分库: 针对的是一个系统中的不同业务进行拆分。

### 水平拆分

- 离散映射：如 mod 或 dayofweek ， 这种类型的映射能够很好的解决热点问题，但带来了数据迁移和历史数据问题。
- 连续映射；如按 id 或 gmt_create_time 的连续范围做映射。这种类型的映射可以避免数据迁移，但又带来热点问题。

### 分库分表规则的设计和配置，长远说来必须满足以下要求

- 可以动态推送修改
- 规则可以分层级叠加，旧规则可以在新规则下继续使用，新规则是旧规则在更宽尺度上的拓展，以此支持新旧规则的兼容，避免数据迁移
- 用 mod 方式时，最好选 2 的指数级倍分库分表，这样方便以后切割。

### 数据迁移

- 停机迁移 是最简单、最安全、最快速的迁移方案，但一般线上业务系统很少允许停机迁移。
- 双写迁移 方案就是同时写两个库，一个是老库，一个是新库。
  - 1.导入历史数据，数据库双写（事务成功以老数据源为准），查询走老数据源，通过定时任务补全新老差异数据
  - 2.新老数据无差异，依旧双写（事务成功以新数据源为准），查询走新数据源
  - 3.稳定运行无误后，下线老数据源

### 主从复制

- MySQL 主从复制涉及到三个线程，一个运行在主节点（log dump thread），其余两个(I/O thread, SQL thread)运行在从节点。
  - Log Dump Thread：当从节点连接主节点时，主节点会创建一个 log dump 线程，用于发送 bin-log 的内容。
  - I/O Thread：当从节点上执行 start slave 命令之后，从节点会创建一个 I/O 线程用来连接主节点，请求主库中更新的 bin-log。I/O 线程接收到主节点 binlog dump 进程发来的更新之后，保存在本地 relay-log 中。
  - SQL Thread：负责读取 relay log 中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。

### 同步模式

- 异步模式（mysql async-mode）：MySQL 增删改操作会全部记录在 binary log 中，当 slave 节点连接 master 时，会主动从 master 处获取最新的 bin log 文件。
- 半同步模式(mysql semi-sync)：这种模式下主节点只需要接收到其中一台从节点的返回信息，就会 commit
- 全同步模式 是指主节点和从节点全部执行了 commit 并确认才会向客户端返回成功。

### 主从复制的延迟问题

- 优化主从节点之间的网络延迟
- 降低 master 负载，以减少 TPS
- 降低 slave 负载，slave 只做备份使用，不提供服务
- 调整 slave 参数：关闭 slave bin-log 等
- 多线程的主从复制：不同 schema 下的表并发提交时的数据不会相互影响，即 slave 节点可以用对 relay log 中不同的 schema 各分配一个 SQL Thread，来重放 relay log 中主库已经提交的事务

### 全局 ID

- 数据库自增 id
- 设置数据库 sequence 或者表自增字段步长
- UUID
- Snowflake 算法
  - |–1 位符号位–|--41 位时间戳–|--10 位机器 ID–|--12 位序列号–|
  - 问题:
    - 时间的准确度问题: 每当进行 NTP 时间校准时，你的机器时间总会向后 回拨 一段时间，这时悲剧就来了：有极大可能性生成重复 ID。
  - 改进:
    - 时间戳由毫秒变为秒
    - 使用环形列表对时间戳对应的序列进行缓存
      - 将时间戳改为秒为单位，同时可以把省出来的位交给序列。此时缓存一个小时的数据（即可以容忍一个小时的时钟回拨）也就只需要缓存 3600 个序列
      - 改进后的 Snowflake 生成的 ID 是这样组成的：|–1 位符号位–|--32 位时间戳–|--10 位机器 ID–|--21 位序列号–|
    - 使用 CAS 操作避免大粒度悲观锁

## 参考资料

> - []()
> - []()
